{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO6AwR5dsaBmkVv5IVH6AyN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YZQCZbczz39P","executionInfo":{"status":"ok","timestamp":1682380132488,"user_tz":420,"elapsed":1296,"user":{"displayName":"Dhatri Gudipelly","userId":"11125027317731508100"}},"outputId":"a10aea68-6308-4c05-8de6-9de067fbe22f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import numpy as np  # linear algebra\n","import pandas as pd # Data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from glob import glob\n","import seaborn as sns\n","from PIL import Image\n","#from imutils import paths\n","import random\n","import pickle\n","import cv2\n","import datetime\n","from pprint import pprint\n","import librosa"],"metadata":{"id":"UFV_qQ7M10l0","executionInfo":{"status":"ok","timestamp":1682379164551,"user_tz":420,"elapsed":3,"user":{"displayName":"Dhatri Gudipelly","userId":"11125027317731508100"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["from tables import file\n","from pandas.core.indexes.multi import F\n","import pandas as pd\n","\n","file1 = pd.read_csv('/content/drive/MyDrive/archive (1)/8/8.benign.csv')\n","file1['label'] = 'benign'\n","file2 = pd.read_csv('/content/drive/MyDrive/archive (1)/8/8.gafgyt.combo.csv')\n","file2['label'] = 'gafgyt combo'\n","file3 = pd.read_csv('/content/drive/MyDrive/archive (1)/8/8.gafgyt.junk.csv')\n","file3['label'] = 'gafgyt junk'\n","file4 = pd.read_csv('/content/drive/MyDrive/archive (1)/8/8.gafgyt.scan.csv')\n","file4['label'] = 'gafgyt scan'\n","file5 = pd.read_csv('/content/drive/MyDrive/archive (1)/8/8.gafgyt.tcp.csv')\n","file5['label'] = 'gafgyt tcp'\n","file6 = pd.read_csv('/content/drive/MyDrive/archive (1)/8/8.gafgyt.udp.csv')\n","file6['label'] = 'gafgyt udp'\n","file7 = pd.read_csv('/content/drive/MyDrive/archive (1)/8/8.mirai.ack.csv')\n","file7['label'] = 'mirai ack'\n","file8 = pd.read_csv('/content/drive/MyDrive/archive (1)/8/8.mirai.scan.csv')\n","file8['label'] = 'mirai scan'\n","file9 = pd.read_csv('/content/drive/MyDrive/archive (1)/8/8.mirai.syn.csv')\n","file9['label'] = 'mirai syn'\n","file10 = pd.read_csv('/content/drive/MyDrive/archive (1)/8/8.mirai.udp.csv')\n","file10['label'] = 'mirai udp'\n","file11 = pd.read_csv('/content/drive/MyDrive/archive (1)/8/8.mirai.udpplain.csv')\n","file11['label'] = 'mirai udpplain'\n","\n","file12 = pd.read_csv('/content/drive/MyDrive/archive (1)/9/9.benign.csv')\n","file12['label'] = 'benign'\n","file13 = pd.read_csv('/content/drive/MyDrive/archive (1)/9/9.gafgyt.combo.csv')\n","file13['label'] = 'gafgyt combo'\n","file14 = pd.read_csv('/content/drive/MyDrive/archive (1)/9/9.gafgyt.junk.csv')\n","file14['label'] = 'gafgyt junk'\n","file15 = pd.read_csv('/content/drive/MyDrive/archive (1)/9/9.gafgyt.scan.csv')\n","file15['label'] = 'gafgyt scan'\n","file16 = pd.read_csv('/content/drive/MyDrive/archive (1)/9/9.gafgyt.tcp.csv')\n","file16['label'] = 'gafgyt tcp'\n","file17 = pd.read_csv('/content/drive/MyDrive/archive (1)/9/9.gafgyt.udp.csv')\n","file17['label'] = 'gafgyt udp'\n","file18 = pd.read_csv('/content/drive/MyDrive/archive (1)/9/9.mirai.ack.csv')\n","file18['label'] = 'mirai ack'\n","file19 = pd.read_csv('/content/drive/MyDrive/archive (1)/9/9.mirai.scan.csv')\n","file19['label'] = 'mirai scan'\n","file20 = pd.read_csv('/content/drive/MyDrive/archive (1)/9/9.mirai.syn.csv')\n","file20['label'] = 'mirai syn'\n","file21 = pd.read_csv('/content/drive/MyDrive/archive (1)/9/9.mirai.udp.csv')\n","file21['label'] = 'mirai udp'\n","file22 = pd.read_csv('/content/drive/MyDrive/archive (1)/9/9.mirai.udpplain.csv')\n","file22['label'] = 'mirai udpplain'\n","\n","file0 = pd.concat([file1, file2])\n","del file1,file2\n","file0 = pd.concat([file0,file3])\n","del file3\n","file0 = pd.concat([file0,file4])\n","del file4\n","file0 = pd.concat([file0,file5])\n","del file5\n","file0 = pd.concat([file0,file6])\n","del file6\n","file0 = pd.concat([file0,file7])\n","del file7\n","file0 = pd.concat([file0,file8])\n","del file8\n","file0 = pd.concat([file0,file9])\n","del file9\n","file0 = pd.concat([file0,file10])\n","del file10\n","file0 = pd.concat([file0,file11])\n","del file11\n","\n","file0 = pd.concat([file0,file12])\n","del file12\n","file0 = pd.concat([file0,file13])\n","del file13\n","file0 = pd.concat([file0,file14])\n","del file14\n","file0 = pd.concat([file0,file15])\n","del file15\n","file0 = pd.concat([file0,file16])\n","del file16\n","file0 = pd.concat([file0,file17])\n","del file17\n","file0 = pd.concat([file0,file18])\n","del file18\n","file0 = pd.concat([file0,file19])\n","del file19\n","file0 = pd.concat([file0,file20])\n","del file20\n","file0 = pd.concat([file0,file21])\n","del file21\n","file0 = pd.concat([file0,file22])\n","del file22\n","\n"],"metadata":{"id":"JRJAVzkl14SZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file0['label'].value_counts()"],"metadata":{"id":"eHT32MSa14sL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()\n","file0.label = le.fit_transform(file0.label)\n","\n","file0"],"metadata":{"id":"8ankEOXs17jS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# assume your DataFrame is named 'df'\n","file0 = file0.replace([np.inf, -np.inf], np.nan)  # replace infinite values with NaN\n","#da = da[da.abs() < np.finfo(np.float64).max]  # remove all rows containing values larger than max float\n","\n","file0 = file0.dropna()\n","\n","# print the new DataFrame shape to verify the infinite or too large values have been removed\n","print(file0.shape)"],"metadata":{"id":"mx79iKxp19Bb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = file0.iloc[:,:-1]"],"metadata":{"id":"Ee87P1hu1-r2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","scaled_features = scaler.fit_transform(file0.iloc[:,:-1])"],"metadata":{"id":"eFS9_y-M2AWW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = pd.DataFrame(scaled_features, columns = data.columns)\n","y = file0.iloc[:,-1]\n","\n","print(X.shape)\n","print(y.shape)"],"metadata":{"id":"tEt9q0072EEt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X= X.values"],"metadata":{"id":"55PyD51M2ELH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from imblearn.under_sampling import RandomUnderSampler\n","\n","rus = RandomUnderSampler(random_state=100)\n","Xrus,Yrus = rus.fit_resample(X,y)"],"metadata":{"id":"gGCa6HW02Gbo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels_full = pd.get_dummies(Yrus,prefix='type')\n","labels_full.head()\n","\n","labels = labels_full.values\n","labels"],"metadata":{"id":"Qb0uqPqa2ILd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(Xrus,labels, test_size=0.2, random_state=100)\n","X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=0.125, random_state=100)\n","\n","print(X_train.shape)\n","print(y_train.shape)\n","print(X_test.shape)\n","print(y_validate.shape)\n","print(y_test.shape)\n"],"metadata":{"id":"FsJ0MCo52J7e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","X_train_cnn = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n","X_test_cnn = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\n","x_validate_cnn = np.reshape(X_validate, (X_validate.shape[0], X_validate.shape[1],1)) "],"metadata":{"id":"bja2ureo2NMm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import keras\n","from keras.utils import np_utils\n","from keras.regularizers import *\n","from keras.initializers import glorot_uniform\n","\n","import keras.backend as K\n","K.clear_session()\n","\n","from keras.models import *\n","from keras.layers import *\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import *\n","from keras.callbacks import *"],"metadata":{"id":"g4HApK132PfO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n","\n","# Define the LeNet model\n","def LeNet(input_shape, num_classes):\n","    model = Sequential()\n","    # First convolutional layer\n","    model.add(Conv1D(6, kernel_size=5, activation='relu', input_shape=input_shape))\n","    model.add(MaxPooling1D(pool_size=2))\n","    # Second convolutional layer\n","    model.add(Conv1D(16, kernel_size=5, activation='relu'))\n","    model.add(MaxPooling1D(pool_size=2))\n","    # Flatten the output from the convolutional layers\n","    model.add(Flatten())\n","    # First fully connected layer\n","    model.add(Dense(120, activation='relu'))\n","    # Second fully connected layer\n","    model.add(Dense(84, activation='relu'))\n","    # Output layer\n","    model.add(Dense(num_classes, activation='softmax'))\n","    return model\n","\n","# Define the input shape and number of classes\n","input_shape =  (X_train.shape[1], 1)\n","num_classes = labels_full.shape[1]\n","\n","# Create the LeNet model\n","model = LeNet(input_shape, num_classes)\n","\n","modelName = 'CNN'\n","# Print the model summary\n","model.summary()"],"metadata":{"id":"1wfW0JuH2QeP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["adam = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n","#sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True) \n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n","                                            patience=3, \n","                                            verbose=1, \n","                                            factor=0.5, \n","                                            learning_rate=0.00001)\n","earlystop = EarlyStopping(monitor = 'val_loss',\n","                          min_delta = 0,\n","                          patience = 10,\n","                          verbose = 1,\n","                          restore_best_weights = True)\n","\n","checkpoint = ModelCheckpoint('./'+modelName+'.h5',\n","                            monitor='val_loss',\n","                             mode='min',\n","                             save_best_only=True,\n","                             save_weights_only=True,\n","                             verbose=1)"],"metadata":{"id":"em5TyI002Ua7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 100\n","batch_size = 512\n","history = model.fit(X_train_cnn,y_train, batch_size=batch_size,\n","    epochs=epochs,\n","    validation_data=(x_validate_cnn,y_validate),\n","    callbacks=[learning_rate_reduction, checkpoint] \n",")\n"],"metadata":{"id":"llLj4qP-2WP9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support,  roc_curve, auc\n","import tensorflow as tf \n","#model = tf.keras.models.load_model('/'+model_name+'.h5')\n","\n","y_pred = model.predict(X_test_cnn)\n","\n","y_pred_cm  = np.argmax(y_pred, axis =1)\n","y_test_cm  = np.argmax(y_test, axis = 1)\n","\n","cm = confusion_matrix(y_test_cm, y_pred_cm) \n","\n","group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n","\n","group_percentages = [\"{0:.2%}\".format(value) for value in cm.flatten()/np.sum(cm)]\n","\n","labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts,group_percentages)]\n","\n","labels = np.asarray(labels).reshape(11,11)\n","\n","label = ['benign','mirai_udp','gafgyt_combo','gafgyt_junk','gafgyt_scan','gafgyt_tcp','gafgyt_udp'\\\n","        ,'mirai_ack','mirai_scan','mirai_syn','mirai_udpplain']\n","\n","plt.figure(figsize=(11,11))\n","sns.heatmap(cm, xticklabels=label, yticklabels=label, annot=labels, fmt='', cmap=\"Blues\", vmin = 0.2);\n","plt.title('Confusion Matrix for'+ modelName+' model')\n","plt.ylabel('True Class')\n","plt.xlabel('Predicted Class')\n","plt.savefig('./'+modelName+'_CM.png')\n","plt.show()"],"metadata":{"id":"0WWrOe9C2ZBH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","print(classification_report(y_test_cm, y_pred_cm, target_names= ['benign','mirai_udp','gafgyt_combo','gafgyt_junk','gafgyt_scan','gafgyt_tcp','gafgyt_udp','mirai_ack','mirai_scan','mirai_syn','mirai_udpplain']))\n","\n","loss, accuracy = model.evaluate(X_test_cnn, y_test, verbose=1)\n","print(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))\n","\n","with open('./'+modelName+'_CR.txt','a') as f:\n","    f.write(classification_report(y_test_cm, y_pred_cm, target_names= ['benign','mirai_udp','gafgyt_combo','gafgyt_junk','gafgyt_scan','gafgyt_tcp','gafgyt_udp','mirai_ack','mirai_scan','mirai_syn','mirai_udpplain']))\n","    f.write(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))"],"metadata":{"id":"Nh6vAZ0g2a8Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from itertools import cycle\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","for i in range(labels.shape[1]):\n","    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","colors = cycle(['blue', 'red', 'green','aqua', 'darkorange', 'orange','fuchsia', 'lime','magenta'])\n","for i, color in zip(range(labels.shape[1]), colors):\n","    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n","             label='ROC curve of class {0} (area = {1:0.2f})'\n","             ''.format(i, roc_auc[i]))\n","plt.plot([0, 1], [0, 1], 'k--', lw=2)\n","plt.xlim([0.0,1.2])\n","plt.ylim([0.0,1.2])\n","plt.ylabel('Recall')\n","plt.xlabel('Fall-out (1-Specificity)')\n","plt.title('Receiver Operating Characteristic (ROC) for '+modelName+' model')\n","plt.legend(loc=\"lower right\")\n","plt.savefig('./'+modelName+'_ROC.png')\n","\n","plt.show()"],"metadata":{"id":"HlC_N1vq2bDF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import precision_score\n","macro_score_rf = precision_score(y_test_cm,y_pred_cm,average='macro')\n","micro_score_rf = precision_score(y_test_cm,y_pred_cm,average='micro')\n","weighted_score_rf = precision_score(y_test_cm,y_pred_cm,average='weighted')\n","\n","#precision scores\n","print(macro_score_rf)\n","print(micro_score_rf)\n","print(weighted_score_rf)\n","\n","from sklearn.metrics import recall_score\n","rmacro_score_rf = recall_score(y_test_cm,y_pred_cm,average='macro')\n","rmicro_score_rf = recall_score(y_test_cm,y_pred_cm,average='micro')\n","rweighted_score_rf = recall_score(y_test_cm,y_pred_cm,average='weighted')\n","\n","#precision scores\n","print(rmacro_score_rf)\n","print(rmicro_score_rf)\n","print(rweighted_score_rf)"],"metadata":{"id":"EHY_V25m2fGX"},"execution_count":null,"outputs":[]}]}